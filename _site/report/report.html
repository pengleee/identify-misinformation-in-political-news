<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2024-12-16">

<title>Identify Linguistic Markers of Misinformation in Political News Articles – DSAN5000 Project</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../assets/gu-logo.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-6bd9cfa162949bde0a231f530c97869d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../report/report.html">Report</a></li><li class="breadcrumb-item"><a href="../report/report.html">web</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">DSAN5000 Project</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/dsan-5000/project-5000-identify-misinformation/" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Home</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../about-the-authors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About the Authors</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../assets/tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Directory Tree</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Technical details</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../technical-details/data-collection/main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Collection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../technical-details/data-cleaning/main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Cleaning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../technical-details/eda/main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exploratory Data Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../technical-details/unsupervised-learning/main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unsupervised Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../technical-details/supervised-learning/main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Supervised Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../technical-details/collaborators-progress-log.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Collaborators Progress Log</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../technical-details/llm-usage-log.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">LLM Usage Log</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Report</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../report/report.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">web</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../report/5000-Project-Report.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">pdf</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#literature-review" id="toc-literature-review" class="nav-link" data-scroll-target="#literature-review">Literature Review</a></li>
  <li><a href="#data-preprocessing" id="toc-data-preprocessing" class="nav-link" data-scroll-target="#data-preprocessing">Data Preprocessing</a>
  <ul class="collapse">
  <li><a href="#data-collectiondata-cleaning" id="toc-data-collectiondata-cleaning" class="nav-link" data-scroll-target="#data-collectiondata-cleaning">Data Collection/Data Cleaning</a>
  <ul class="collapse">
  <li><a href="#liar-dataset-8" id="toc-liar-dataset-8" class="nav-link" data-scroll-target="#liar-dataset-8">LIAR dataset </a></li>
  <li><a href="#media-cloud-api-data-9" id="toc-media-cloud-api-data-9" class="nav-link" data-scroll-target="#media-cloud-api-data-9">Media Cloud API Data </a></li>
  <li><a href="#news-api-data-10" id="toc-news-api-data-10" class="nav-link" data-scroll-target="#news-api-data-10">News API Data </a></li>
  </ul></li>
  <li><a href="#exploratory-data-analysis-eda" id="toc-exploratory-data-analysis-eda" class="nav-link" data-scroll-target="#exploratory-data-analysis-eda">Exploratory Data Analysis (EDA)</a>
  <ul class="collapse">
  <li><a href="#google-trends-analysis" id="toc-google-trends-analysis" class="nav-link" data-scroll-target="#google-trends-analysis">Google Trends Analysis</a></li>
  <li><a href="#news-source-analysis" id="toc-news-source-analysis" class="nav-link" data-scroll-target="#news-source-analysis">News Source Analysis</a></li>
  <li><a href="#text-analysis" id="toc-text-analysis" class="nav-link" data-scroll-target="#text-analysis">Text Analysis</a></li>
  <li><a href="#visualization" id="toc-visualization" class="nav-link" data-scroll-target="#visualization">Visualization</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#methodology" id="toc-methodology" class="nav-link" data-scroll-target="#methodology">Methodology</a>
  <ul class="collapse">
  <li><a href="#unsupervised-machine-learning" id="toc-unsupervised-machine-learning" class="nav-link" data-scroll-target="#unsupervised-machine-learning">Unsupervised Machine Learning</a></li>
  <li><a href="#supervised-machine-learning" id="toc-supervised-machine-learning" class="nav-link" data-scroll-target="#supervised-machine-learning">Supervised Machine Learning</a>
  <ul class="collapse">
  <li><a href="#load-and-explore-the-dataset" id="toc-load-and-explore-the-dataset" class="nav-link" data-scroll-target="#load-and-explore-the-dataset">Load and Explore the Dataset</a></li>
  <li><a href="#preprocess-text-data" id="toc-preprocess-text-data" class="nav-link" data-scroll-target="#preprocess-text-data">Preprocess Text Data</a></li>
  <li><a href="#extract-linguistic-features" id="toc-extract-linguistic-features" class="nav-link" data-scroll-target="#extract-linguistic-features">Extract Linguistic Features</a></li>
  <li><a href="#correlate-features-with-misinformation" id="toc-correlate-features-with-misinformation" class="nav-link" data-scroll-target="#correlate-features-with-misinformation">Correlate Features with Misinformation</a></li>
  <li><a href="#sentiment-analysis" id="toc-sentiment-analysis" class="nav-link" data-scroll-target="#sentiment-analysis">Sentiment Analysis</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#results-and-analysis" id="toc-results-and-analysis" class="nav-link" data-scroll-target="#results-and-analysis">Results and Analysis</a>
  <ul class="collapse">
  <li><a href="#unsupervised-machine-learning-results" id="toc-unsupervised-machine-learning-results" class="nav-link" data-scroll-target="#unsupervised-machine-learning-results">Unsupervised Machine Learning Results</a>
  <ul class="collapse">
  <li><a href="#dimensionality-reduction" id="toc-dimensionality-reduction" class="nav-link" data-scroll-target="#dimensionality-reduction">Dimensionality Reduction</a></li>
  <li><a href="#topic-modeling" id="toc-topic-modeling" class="nav-link" data-scroll-target="#topic-modeling">Topic Modeling</a></li>
  <li><a href="#cross-tabulation-and-truthfulness-analysis" id="toc-cross-tabulation-and-truthfulness-analysis" class="nav-link" data-scroll-target="#cross-tabulation-and-truthfulness-analysis">Cross-Tabulation and Truthfulness Analysis</a></li>
  </ul></li>
  <li><a href="#supervised-machine-learning-results" id="toc-supervised-machine-learning-results" class="nav-link" data-scroll-target="#supervised-machine-learning-results">Supervised Machine Learning Results</a>
  <ul class="collapse">
  <li><a href="#model-performance" id="toc-model-performance" class="nav-link" data-scroll-target="#model-performance">Model Performance</a></li>
  <li><a href="#sentiment-analysis-1" id="toc-sentiment-analysis-1" class="nav-link" data-scroll-target="#sentiment-analysis-1">Sentiment Analysis</a></li>
  <li><a href="#limitations" id="toc-limitations" class="nav-link" data-scroll-target="#limitations">Limitations</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a>
  <ul class="collapse">
  <li><a href="#key-findings" id="toc-key-findings" class="nav-link" data-scroll-target="#key-findings">Key Findings</a></li>
  <li><a href="#implications" id="toc-implications" class="nav-link" data-scroll-target="#implications">Implications</a></li>
  <li><a href="#future-work" id="toc-future-work" class="nav-link" data-scroll-target="#future-work">Future Work</a></li>
  <li><a href="#final-thoughts" id="toc-final-thoughts" class="nav-link" data-scroll-target="#final-thoughts">Final Thoughts</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../report/report.html">Report</a></li><li class="breadcrumb-item"><a href="../report/report.html">web</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Identify Linguistic Markers of Misinformation in Political News Articles</h1>
<p class="subtitle lead">DSAN5000 Final Project Report, 2024 Fall</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Authors</div>
    <div class="quarto-title-meta-contents">
             <p>Peng Li </p>
             <p>Jonah Lichtenthal </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">December 16, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p><br> <strong>Keywords:</strong> Machine Learning, Fake News, Misinformation Detection, Sentiment Analysis, Topic modeling, LIAR, POS Tagging</p>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>In the digital age, the prevalence of misinformation, particularly in political news, has emerged as a critical challenge, undermining public trust and the credibility of information sources. The term "fake news" has evolved into a widespread descriptor of this phenomenon, capturing attention across media platforms and influencing societal discourse. Addressing this issue is essential to fostering informed decision-making and ensuring democratic integrity.</p>
<p>This report explores the linguistic markers of misinformation in political news articles, focusing on their evolution over time and their correlation with perceived credibility. By leveraging advanced machine learning techniques, we aim to identify and analyze the textual patterns that distinguish misinformation from reliable reporting. Our research seeks to provide actionable insights into how misinformation is constructed and disseminated, contributing to the development of robust detection methods.</p>
<p>In this paper, we will conduct a comprehensive overview of fake news in an attempt to explain this phenomenon. Through this analysis, we hope to gain a deeper understanding of the rising concern revolving around fake news and contribute to the ongoing conversation about ensuring our news is reliably fact-checked.</p>
<p>First, however, in order to fully understand our topic, we have come up with 5 research questions that we will also address throughout this paper:</p>
<ol type="1">
<li><p>How do linguistic patterns of misinformation differ across political ideologies?</p></li>
<li><p>How do linguistic markers of misinformation evolve over time in response to political events (like 2024 US Election)?</p></li>
<li><p>Can multimodal features (text + metadata) improve the detection of linguistic markers in misinformation?</p></li>
<li><p>What role does sentiment polarity play in distinguishing misinformation from credible political articles?</p></li>
<li><p>How does the use of rhetorical devices correlate with the perceived credibility of misinformation articles?</p></li>
</ol>
<p>Through this comprehensive analysis, we aim to deepen our understanding of the mechanisms underlying fake news and offer a foundation for future advancements in automated misinformation detection.</p>
<p>The rest of our paper will adhere to the following format:</p>
<p><strong>Literature Review:</strong> In order to get a better the current state in the field of fake news detection we will be going through a comprehensive overview of previous work done on the topic. The extent of our literature review contains some of the most cited papers in the space as well as the paper that introduces the benchmarking dataset we will use in our paper.</p>
<p><strong>Data Preprocessing:</strong> In this section, data will be prepared for processing in machine learning. This includes data collection, data cleaning, and exploratory data analysis (EDA).</p>
<p>Starting with data collection, we will discuss each dataset we obtained that is related to our topic. Although not all of these sources may be used in our analysis, we include them as a valuable resource for others who may wish to utilize them in their own work.</p>
<p>Moving on to cleaning our data, we will discuss the methods necessary to transform the raw data into something we can use later for more complex analyses.</p>
<p>Finally, we move on to our EDA. In this section, we will use the art of EDA as a tool to help us better understand our data. Specifically, these tools will help identify correlations within the dataset and uncover any meaningful patterns present. These correlations and patterns can then be used later as a tool to create more robust and accurate models.</p>
<p><strong>Exploratory and Predictive Modeling:</strong></p>
<p>This is the technical section of our report where we will talk about the supervised and unsupervised machine learning techniques we used. We will talk through each of the models we used with visualizations of results scattered through to enhance understandability.</p>
<p>For unsupervised we start by bucketing our data into 6 topics using NMF topic modeling. From here we used a dimensionality reduction technique known as t-SNE to visualize each of these buckets created by the NMF model in a low dimensional space and analyze for clustering. Finally we will see if each topic has differing amounts of truthfulness to make a prediction on how well we will be able to create a model that can differential truthful statements from misleading ones.</p>
<p>For supervised learning we analyze linguistic patterns and sentiment in misinformation.</p>
<p><strong>Conclusion:</strong></p>
<p>In this section we will state our non-technical conclusions. Using the results we obtained we will comment on how these results are significant and add to the ongoing conversation about the recent emergence of fake news.</p>
</section>
<section id="literature-review" class="level1">
<h1>Literature Review</h1>
<ol type="1">
<li><p><strong>Fake News Detection on Social Media: A Data Mining Perspective</strong><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p><em>Description:</em> This is one of the most cited articles on Google Scholar about fake news detection, likely due to its extensive scope. It provides a comprehensive overview, including an exploration of what constitutes fake news, common challenges, and a detailed outline of various detection approaches. These include linguistic approaches (analyzing how the post is worded), visual approaches (detecting fake images), user-based approaches (evaluating the credibility of the poster), post-based approaches (examining how the post was received), and network-based approaches (analyzing where the post was shared).</p></li>
<li><p><strong>A Survey on Natural Language Processing for Fake News Detection</strong><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p><em>Description:</em> This is one of the most comprehensive surveys on fake news detection using Natural Language Processing. It begins by defining fake news and related tasks such as fact-checking, rumor detection, stance detection, and sentiment analysis. The paper provides an extensive review of datasets and methods, covering classification and regression tasks for fake news detection. The approaches include SVMs, Naive Bayes, LSTMs, CNNs, and attention mechanisms. The paper also discusses dataset limitations and recommendations for future work.</p></li>
<li><p><strong>Automatic Detection of Fake News</strong><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<p><em>Description:</em> This is an innovative study on fake news detection, this article stands out for introducing datasets designed for detecting fake news across multiple domains. The paper provides a comprehensive exploration of linguistic differences between fake and legitimate news, examining features such as syntax, readability, and psycholinguistics. The paper builds models using SVMs that achieve up to 78% accuracy.</p></li>
<li><p><strong>Towards News Verification: Deception Detection Methods for News Discourse</strong><a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<p><em>Description:</em> This article investigated whether rhetorical structures and discourse features in news text could reliably predict its veracity. Using data from NPR’s “Bluff the Listener” segment, they employed Rhetorical Structure Theory (RST) and Vector Space Modelling (VSM) to analyse the discourse</p></li>
<li><p><strong>Do You Speak Disinformation? Computational Detection of Deceptive News-Like Content Using Linguistic and Stylistic Features</strong><a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
<p><em>Description:</em> This article leverage explainable machine learning, specifically tree-based models, to analyze linguistic and stylistic features distinguishing genuine from deceptive articles. A substantial, diverse dataset of manually annotated articles is used to train and test the models, addressing limitations of previous studies which often relied on smaller or biased datasets. The results reveal specific linguistic patterns—such as headline length, use of exclamation marks, and presence of past tense verbs—that significantly contribute to accurate disinformation detection, providing valuable insights for journalists, fact-checkers, and algorithm developers. The study ultimately aims to improve automated disinformation detection methods and enhance public understanding of the “language of fake news”.</p></li>
<li><p><strong>"Liar, Liar Pants on Fire": A New Benchmark Dataset for Fake News Detection</strong><a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<p><em>Description:</em><br>
This paper introduces LIAR, a new, significantly larger dataset (12,836 manually labelled statements) for fake news detection, addressing the previous lack of sufficient labelled data for robust machine learning models. The dataset, sourced from PolitiFact.com, includes rich metadata such as speaker affiliation and context, enabling more sophisticated analysis than previous, smaller datasets. The authors evaluate various machine learning models on LIAR, including a novel hybrid convolutional neural network that integrates textual and metadata features, demonstrating that incorporating metadata improves fake news detection accuracy. The paper’s purpose is to provide a valuable resource for the research community and showcase the benefits of using this enhanced dataset for improving fake news detection algorithms</p></li>
</ol>
</section>
<section id="data-preprocessing" class="level1">
<h1>Data Preprocessing</h1>
<p>In this section, we will discuss the collection and cleaning of data sources relevant to our topic. Although not all of these sources may be used in our analysis, we include them as a valuable resource for others who may wish to utilize them in their own work. We then will explore our datasets in an attempt to better visualize and understand potential trends within the data.</p>
<section id="data-collectiondata-cleaning" class="level2">
<h2 class="anchored" data-anchor-id="data-collectiondata-cleaning">Data Collection/Data Cleaning</h2>
<section id="liar-dataset-8" class="level3">
<h3 class="anchored" data-anchor-id="liar-dataset-8">LIAR dataset <a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></h3>
<p>The main dataset we will use to train and test our model is the LIAR dataset. This dataset is a benchmark dataset for fake news detection, containing 12.8K human-labeled short statements from various contexts, including news articles, TV or radio interviews, campaign speeches, social media posts, and fact-checking websites. Contained within the dataset are the statements made, meta information about the statements (who said it, where it was posted), and a truth value which measures the validity of the statement. The following is a table where I list each of these truth statements ranking them from 1 (least truthful) to 6 (most truthful):</p>
<div id="tab:my_label">
<table class="caption-top table">
<caption>Ranking of truth values</caption>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">Pants on Fire</td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: center;">False</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3</td>
<td style="text-align: center;">Barely-True</td>
</tr>
<tr class="even">
<td style="text-align: center;">4</td>
<td style="text-align: center;">Half-True</td>
</tr>
<tr class="odd">
<td style="text-align: center;">5</td>
<td style="text-align: center;">Mostly-True</td>
</tr>
<tr class="even">
<td style="text-align: center;">6</td>
<td style="text-align: center;">True</td>
</tr>
</tbody>
</table>
</div>
<p>This is an already cleaned dataset so there was not much data cleaning required. The only change we made was converting the TSV files to CSV files as these are often easier since they can be examined in excel and are just generally a more common format for datasets.</p>
</section>
<section id="media-cloud-api-data-9" class="level3">
<h3 class="anchored" data-anchor-id="media-cloud-api-data-9">Media Cloud API Data <a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></h3>
<p>This data comes from a comprehensive platform offering access to a vast collection of news articles and media content. The API enables programmatic access to analyze news coverage, track topics across different media sources, and study media ecosystems over time.</p>
</section>
<section id="news-api-data-10" class="level3">
<h3 class="anchored" data-anchor-id="news-api-data-10">News API Data <a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a></h3>
<p>This data comes from a simple HTTP REST API for searching and retrieving live articles from all over the web. It provides access to headlines and articles from over 80,000 news sources worldwide, supporting features like keyword search, source filtering, and date range queries.</p>
<p>This data was the most complicated to extract into a useful format due the the data originally formatted as a JSON file. Reading in the JSON file and looking through the different keys avaialable we were able to extract the data needed ending up with a csv dataframe containing 10 attributes which include data such as article content, article dates/times, article source, article author, and article title.</p>
<p>In this section we also attempted to label each of the articles using a Open AI’s API so we could test our model on a second dataset of raw data. Unfortunately, what we found is that none of the OpenAI API models have access to real-time data in order to validate the claims. We did some research into other LLM APIs and found that none of the large LLM APIs have access to real-time or constantly updated information.</p>
</section>
</section>
<section id="exploratory-data-analysis-eda" class="level2">
<h2 class="anchored" data-anchor-id="exploratory-data-analysis-eda">Exploratory Data Analysis (EDA)</h2>
<section id="google-trends-analysis" class="level3">
<h3 class="anchored" data-anchor-id="google-trends-analysis">Google Trends Analysis</h3>
<p>To start out our EDA process we return to our introduction to visualize what the trend of fake news may look like. The graph from google trends:</p>
<div class="center">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figcaption>Google trends graph for popularity of the term “fake news”<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></figcaption>
<p><img src="../assets/5000-images/Fake News Google Trends.JPG" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<p>As can be seen the the term "fake news" was not really used before 2016. Interestingly this is when the extremely controversial candidate of Donald Trump emerged onto the scene. Trump’s often criticism of news sources likely impacted the public’s view on these sources. While this large uptick in 2016 could be seen as the term becoming popular, we also see a large increase in usage in 2020 suggesting election cycles may be having an effect on people’s opinions of the news.</p>
</section>
<section id="news-source-analysis" class="level3">
<h3 class="anchored" data-anchor-id="news-source-analysis">News Source Analysis</h3>
<p>In this section we will explore the sources of our data in order to have a more concrete understanding of where are data is from. This analysis will contain the following:</p>
<ul>
<li><p>Distribution of truth labels in fact-checked statements</p></li>
<li><p>Temporal patterns in news coverage</p></li>
<li><p>Source analysis of news articles</p></li>
</ul>
<p>The following is a barchart containing the most popular sources in our dataset along with the number of times that source appeared.</p>
<div class="center">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figcaption>Distribution of News API Data by Source</figcaption>
<p><img src="../assets/5000-EDA/news-source.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<p>From the distribution of News API Data by source, we can see the sources are highly unbalanced. The amount of news gathered from NPR, BBC News and Business Insider is far greater than the other sources.</p>
</section>
<section id="text-analysis" class="level3">
<h3 class="anchored" data-anchor-id="text-analysis">Text Analysis</h3>
<p>In this section we will explore our textual data in order to have a more concrete understanding of what this data looks like. This analysis will contain the following:</p>
<ul>
<li><p>Word count distributions</p></li>
<li><p>Word clouds to visualize common themes</p></li>
<li><p>Statement length analysis</p></li>
</ul>
<p>For a dataset on news articles, the non-numerical data contains more value than the numerical data. Especially given our task of evaluating the truthfulness of a statement, the textual data is very important. Identifying which words occur most frequently offers valuable insights that help refine and improve our approach to identify misinformation.<br>
To visualize this concept, three wordclouds have been created. These wordclouds show the most common words in each of our datasets. Common words that likely have give no information into whether a word is part of a question or an answer have been removed from the visualizations. These words commonly called stopwords such as "the", "a", and "to" were removed.</p>
<div class="center">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figcaption>LIAR Word Cloud</figcaption>
<p><img src="../assets/5000-EDA/liar-wordcloud.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="center">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figcaption>MediaCloud API Word Cloud</figcaption>
<p><img src="../assets/5000-EDA/cd-wordcloud.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="center">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figcaption>News API Word Cloud</figcaption>
<p><img src="../assets/5000-EDA/news-wordcloud.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<p>These wordclouds are generated from the article titles to visualize the most common words. We can obviously observe that the names of presidents, president candidates and some socioeconomic celebrities appear frequently in all the wordclouds.</p>
<p>More specifically, from these three wordclouds we can see a lot of similarities and also some differences. Certain broad words are common in all three datasets such as "state", "say", and "america". Looking closely into the differences we see that these three datasets are likely from different time periods. This is because the News API dataset has more recent names such as Elon Musk and Donald Trump where the other two datasets focus more on Obama and his policies. Looking closer at the data sources we can see this does seem to be the case.</p>
<p>In the next two bar charts we are plotting the lengths of the titles of articles from both the MediaCloud and NewsAPI data.</p>
<div class="center">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figcaption>Distribution of MediaCloud API by Article Title Length</figcaption>
<p><img src="../assets/5000-EDA/mc-title-length.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="center">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figcaption>Distribution of News API by Article Title Length</figcaption>
<p><img src="../assets/5000-EDA/news-length.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<p>We can see from these barcharts that the typical title length is around 75 characters both from MediaCloud API data and News API data, which may imply some inherent characteristics of political news titles.</p>
</section>
<section id="visualization" class="level3">
<h3 class="anchored" data-anchor-id="visualization">Visualization</h3>
<ul>
<li><p>Distribution plots of key variables</p></li>
<li><p>Time series analysis of publication patterns</p></li>
<li><p>Categorical data visualization</p></li>
</ul>
</section>
</section>
</section>
<section id="methodology" class="level1">
<h1>Methodology</h1>
<section id="unsupervised-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="unsupervised-machine-learning">Unsupervised Machine Learning</h2>
<p>The first unsupervised technique we used in a dimensionality reduction technique. The goal of such techniques is to compress the data down from a large number of attributes to 2-3 attributes so that we can visualize these attributes. There’s different options on how to do this with the main two being t-SNE and PCA. For our analysis we chose to use t-SNE due to the non-linear transformations the technique brings which can help show complex non-linear clusters that PCA would not be able to visualize in the same way.</p>
<p>Given the most important factors in our data are textual we will be working with this type of data throughout this analysis which does add some complexities. Our workflow is as follows:</p>
<ol type="1">
<li><p><strong>Clean Text:</strong> We start by removing punctuation marks, numbers, and replacing all uppercase letters with lowercase ones. We will then remove common words that likely have give no information into the legitimacy of a news source. These words commonly called stop words such as “the”, “a”, and “to” were removed using nltk.corpus’s stop words list.</p></li>
<li><p><strong>Text Vectorization:</strong> Next we will vectorize our data using the TfidfVectorizer. The point of this is to covert our textual data into a numerical format that can be processed by and learned from by a computer.</p></li>
<li><p><strong>NMF Model:</strong> The next step is to use NMF topic modeling to bin the different words in our model into 6 different topics. These topics are assigned by the model with the only hyperparaemter we chose being the number of topics as 6. We chose this to explore how closely these 6 randomly generated clusters would align with the 6 truth categories. If we see that these topics assigned by the model have well defined clusters and contain largely one of the truth categories this would be a very good sign that we could use supervised learning techniques to predict the truthfulness of a statement. However, NMF doesn’t inherently align its clusters with external categories, so the clusters might not align perfectly.</p></li>
<li><p><strong>Plot Topics:</strong> Here we simply take the results from the previous NMF model to create a graphic that shows the most common words in each topic.</p>
<div class="center">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figcaption>Most common words in each NMFtopic</figcaption>
<p><img src="../assets/5000-images/Common Words.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<p>While we do see certain words such as "texas" appear in multiple topics these topics seem to be well seperated.</p></li>
<li><p><strong>t-SNE:</strong> Finally we get to t-SNE our dimensionality reduction technique that we will use the lower the number of dimensions in our text dataset in order to plot it in a 2 dimensional plane.</p></li>
<li><p><strong>Plot t-SNE:</strong> Again, here we simply take the results from the previous model and plot them to create a 2 dimensional graph of our textual data color coded by the topics created by the NMF model in step 3.</p>
<div class="center">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figcaption>t-SNE Visualization</figcaption>
<p><img src="../assets/5000-images/t-SNE Visualization.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<p>From this result we can see there seems to be decently well defined clusters which suggests there is an accurate way to segment the data.</p></li>
<li><p><strong>Examine results</strong>: Our final step is to compare these results to our actual truth values to see if there’s any correlation between truth values and our model made topic modeling. If the truth values of these different clusters differ, this would suggest we could nicely separate our data by truth values as is our goal.</p>
<p>We will start by using a crosstab to visualize the amount of each truth type in each group</p>
<div class="center">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figcaption>Crosstable of truth values vs NMF topics</figcaption>
<p><img src="../assets/5000-images/5000 Project Report Crosstable 2.JPG" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<p>We won’t spend too much time on this graphic as it’s a bit much. Instead we have included it for reference and will create a binned the truth types into two categories. The table that follows will contain the following columns for each of the NMF topics created earlier:</p>
<p><strong>Falses:</strong> Number of pants-on-fire statements + number of false statements + number of barely-true statements</p>
<p><strong>Truths:</strong> Number of half-true statements + number of mostly-true statements + number of true statements</p>
<p><strong>Ratio:</strong> This contains the ratio of how many more true statements there are then false statements as defined above <span class="math inline">\(\frac{Truths}{Falses}\)</span></p>
<div class="center">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figcaption>Binned crosstable of truth values vs NMF topics</figcaption>
<p><img src="../assets/5000-images/Ratios.JPG" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<p>From here we can see that the different topics do have significantly different truth ratios with topic 1 having 2.37 times more truths than falses and topic 2 having almost 20% less truths than falses. It is important to reference above what we have defined as truths and falses to understand the full context of this result.</p></li>
</ol>
<p>Combining all of our findings from this section we were able to visualize well separated clusters and that these clusters have a pretty significantly different amount of truthful statements in each topics. This suggests we will be able to create a model in the supervised learning section that is able to differentiate true and false statements.</p>
</section>
<section id="supervised-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="supervised-machine-learning">Supervised Machine Learning</h2>
<p>In this part we mainly implement supervised learning on <code>LIAR</code> dataset to identify linguistic markers.</p>
<section id="load-and-explore-the-dataset" class="level3">
<h3 class="anchored" data-anchor-id="load-and-explore-the-dataset">Load and Explore the Dataset</h3>
<p>The dataset is loaded and explored to understand its structure and contents. The <code>LIAR</code> dataset consists of 10,240 entries with 14 columns, including <code>ID</code>, <code>Label</code>, <code>Statement</code>, <code>Subjects</code>, <code>Speaker</code>, <code>Job_Title</code>, <code>State_Info</code>, <code>Party</code>, <code>Barely_True_Count</code>, <code>False_Count</code>, <code>Half_True_Count</code>, <code>Mostly_True_Count</code>, <code>Pants_On_Fire_Count</code>, and <code>Context</code>.</p>
</section>
<section id="preprocess-text-data" class="level3">
<h3 class="anchored" data-anchor-id="preprocess-text-data">Preprocess Text Data</h3>
<p>Text data is preprocessed to remove stopwords, punctuation, and to tokenize the text. This step is crucial for extracting meaningful features from the text. The preprocessing function tokenizes the text, removes non-alphanumeric tokens, and filters out stopwords and punctuation.</p>
</section>
<section id="extract-linguistic-features" class="level3">
<h3 class="anchored" data-anchor-id="extract-linguistic-features">Extract Linguistic Features</h3>
<p><strong>Part-of-Speech (POS)</strong> tagging is a process of marking up a word in a text (corpus) as corresponding to a particular part of speech, based on both its definition and its context. Here are some common POS tags and their meanings:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>POS Tag</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>NN</strong></td>
<td>Noun, singular or mass</td>
</tr>
<tr class="even">
<td><strong>NNS</strong></td>
<td>Noun, plural</td>
</tr>
<tr class="odd">
<td><strong>VB</strong></td>
<td>Verb, base form</td>
</tr>
<tr class="even">
<td><strong>VBD</strong></td>
<td>Verb, past tense</td>
</tr>
<tr class="odd">
<td><strong>VBG</strong></td>
<td>Verb, gerund or present participle</td>
</tr>
<tr class="even">
<td><strong>VBZ</strong></td>
<td>Verb, 3rd person singular present</td>
</tr>
<tr class="odd">
<td><strong>JJ</strong></td>
<td>Adjective</td>
</tr>
<tr class="even">
<td><strong>RB</strong></td>
<td>Adverb</td>
</tr>
<tr class="odd">
<td><strong>IN</strong></td>
<td>Preposition or subordinating conjunction</td>
</tr>
<tr class="even">
<td><strong>CD</strong></td>
<td>Cardinal number</td>
</tr>
</tbody>
</table>
<p><br> Linguistic features are extracted using TF-IDF for lexical features and POS tagging for syntactic features. The TF-IDF vectorizer is used to transform the cleaned text into a matrix of TF-IDF features. Additionally, POS tagging is performed to extract syntactic features, which are then counted and stored. However, in our research we don’t find a significant correlation between POS tagging and truthfulness categories.</p>
<div class="center">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figcaption>Adjective Usage by Label</figcaption>
<p><img src="../assets/5000-supervised-learning/adj-pos.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</section>
<section id="correlate-features-with-misinformation" class="level3">
<h3 class="anchored" data-anchor-id="correlate-features-with-misinformation">Correlate Features with Misinformation</h3>
<p>The data is split into training and testing sets, and a RandomForestClassifier is trained to predict the labels. The classifier’s performance is evaluated using precision, recall, and F1-score metrics. The results indicate varying levels of accuracy across different truthfulness categories.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th></th>
<th style="text-align: right;">precision</th>
<th style="text-align: right;">recall</th>
<th style="text-align: right;">f1-score</th>
<th style="text-align: right;">support</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>barely-true</td>
<td style="text-align: right;">0.19</td>
<td style="text-align: right;">0.15</td>
<td style="text-align: right;">0.17</td>
<td style="text-align: right;">482</td>
</tr>
<tr class="even">
<td>false</td>
<td style="text-align: right;">0.24</td>
<td style="text-align: right;">0.33</td>
<td style="text-align: right;">0.28</td>
<td style="text-align: right;">603</td>
</tr>
<tr class="odd">
<td>half-true</td>
<td style="text-align: right;">0.26</td>
<td style="text-align: right;">0.27</td>
<td style="text-align: right;">0.26</td>
<td style="text-align: right;">675</td>
</tr>
<tr class="even">
<td>mostly-true</td>
<td style="text-align: right;">0.24</td>
<td style="text-align: right;">0.28</td>
<td style="text-align: right;">0.26</td>
<td style="text-align: right;">582</td>
</tr>
<tr class="odd">
<td>pants-fire</td>
<td style="text-align: right;">0.23</td>
<td style="text-align: right;">0.11</td>
<td style="text-align: right;">0.15</td>
<td style="text-align: right;">236</td>
</tr>
<tr class="even">
<td>true</td>
<td style="text-align: right;">0.22</td>
<td style="text-align: right;">0.17</td>
<td style="text-align: right;">0.19</td>
<td style="text-align: right;">494</td>
</tr>
<tr class="odd">
<td>accuracy</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;">0.23</td>
<td style="text-align: right;">3072</td>
</tr>
<tr class="even">
<td>macro avg</td>
<td style="text-align: right;">0.23</td>
<td style="text-align: right;">0.22</td>
<td style="text-align: right;">0.22</td>
<td style="text-align: right;">3072</td>
</tr>
<tr class="odd">
<td>weighted avg</td>
<td style="text-align: right;">0.23</td>
<td style="text-align: right;">0.23</td>
<td style="text-align: right;">0.23</td>
<td style="text-align: right;">3072</td>
</tr>
</tbody>
</table>
<p>Feature importance is analyzed to understand which linguistic markers are most indicative of misinformation. The top 10 features are visualized using a bar plot, highlighting the most important lexical features identified by the TF-IDF vectorizer.</p>
<div class="center">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figcaption>Top Linguistic Markers</figcaption>
<p><img src="../assets/5000-supervised-learning/top-linguistic-markers.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</section>
<section id="sentiment-analysis" class="level3">
<h3 class="anchored" data-anchor-id="sentiment-analysis">Sentiment Analysis</h3>
<p>Sentiment analysis is performed using two methods:</p>
<ul>
<li><p><strong>VADER Sentiment Analysis</strong>: The VADER sentiment analyzer is used to calculate sentiment scores for the cleaned text. The sentiment scores are categorized into positive, negative, and neutral labels. The distribution of sentiment across different truthfulness categories is visualized using a count plot.</p>
<div class="center">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figcaption>VADER Sentiment Distribution Across Truthfulness Categories</figcaption>
<p><img src="../assets/5000-supervised-learning/vader-sentiment.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div></li>
<li><p><strong>Hugging Face Transformers</strong>: The Hugging Face <em>pipeline</em> for sentiment analysis is used to classify the sentiment of the cleaned text. The sentiment labels are then grouped by truthfulness categories and visualized using a count plot.</p>
<div class="center">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figcaption>Distilbert Sentiment Distribution Across Truthfulness Categories</figcaption>
<p><img src="../assets/5000-supervised-learning/distilbert-sentiment.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div></li>
</ul>
</section>
</section>
</section>
<section id="results-and-analysis" class="level1">
<h1>Results and Analysis</h1>
<section id="unsupervised-machine-learning-results" class="level2">
<h2 class="anchored" data-anchor-id="unsupervised-machine-learning-results">Unsupervised Machine Learning Results</h2>
<section id="dimensionality-reduction" class="level3">
<h3 class="anchored" data-anchor-id="dimensionality-reduction">Dimensionality Reduction</h3>
<p>Using t-SNE for dimensionality reduction, we visualized clusters derived from the textual features of news statements. The resulting plot revealed well-defined clusters, suggesting distinct patterns in the data. The separation between clusters indicates that linguistic markers can differentiate categories of misinformation effectively.</p>
</section>
<section id="topic-modeling" class="level3">
<h3 class="anchored" data-anchor-id="topic-modeling">Topic Modeling</h3>
<p>Applying NMF for topic modeling, six topics were identified, with each characterized by distinct linguistic features. While some overlap in keywords (e.g., <em>Texas</em>) was observed, most topics demonstrated meaningful separations. A key observation was that certain topics correlated strongly with the “truth values” in the LIAR dataset. For example:</p>
<ul>
<li><p>Topic 1: Had a truth-to-false ratio of 2.37, suggesting a higher association with truthful statements.</p></li>
<li><p>Topic 2: Exhibited a 20% higher concentration of false statements, reinforcing its alignment with misinformation patterns.</p></li>
</ul>
</section>
<section id="cross-tabulation-and-truthfulness-analysis" class="level3">
<h3 class="anchored" data-anchor-id="cross-tabulation-and-truthfulness-analysis">Cross-Tabulation and Truthfulness Analysis</h3>
<p>By binning truth values into “True” and “False” categories, we observed significant variability in the distribution across topics. This highlights that the NMF-generated topics capture meaningful linguistic markers that correlate with the veracity of statements. These insights lay a strong foundation for supervised learning.</p>
</section>
</section>
<section id="supervised-machine-learning-results" class="level2">
<h2 class="anchored" data-anchor-id="supervised-machine-learning-results">Supervised Machine Learning Results</h2>
<section id="model-performance" class="level3">
<h3 class="anchored" data-anchor-id="model-performance">Model Performance</h3>
<p>We implemented a Random Forest Classifier on the LIAR dataset, achieving the following performance metrics across six truth categories:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">Category</th>
<th style="text-align: left;">Precision</th>
<th style="text-align: left;">Recall</th>
<th style="text-align: left;">F1-Score</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Barely-True</td>
<td style="text-align: left;">0.19</td>
<td style="text-align: left;">0.15</td>
<td style="text-align: left;">0.17</td>
</tr>
<tr class="even">
<td style="text-align: left;">False</td>
<td style="text-align: left;">0.24</td>
<td style="text-align: left;">0.33</td>
<td style="text-align: left;">0.28</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Half-True</td>
<td style="text-align: left;">0.26</td>
<td style="text-align: left;">0.27</td>
<td style="text-align: left;">0.26</td>
</tr>
<tr class="even">
<td style="text-align: left;">Mostly-True</td>
<td style="text-align: left;">0.24</td>
<td style="text-align: left;">0.28</td>
<td style="text-align: left;">0.26</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Pants-on-Fire</td>
<td style="text-align: left;">0.23</td>
<td style="text-align: left;">0.11</td>
<td style="text-align: left;">0.15</td>
</tr>
<tr class="even">
<td style="text-align: left;">True</td>
<td style="text-align: left;">0.22</td>
<td style="text-align: left;">0.17</td>
<td style="text-align: left;">0.19</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Overall</td>
<td style="text-align: left;">0.23</td>
<td style="text-align: left;">0.23</td>
<td style="text-align: left;">0.23</td>
</tr>
</tbody>
</table>
<p>While the model’s overall accuracy remains modest, its ability to differentiate between truthfulness categories provides valuable insights into linguistic markers of misinformation.</p>
</section>
<section id="sentiment-analysis-1" class="level3">
<h3 class="anchored" data-anchor-id="sentiment-analysis-1">Sentiment Analysis</h3>
<ul>
<li><p><strong>VADER Sentiment Analysis</strong>: The analysis revealed distinct sentiment distributions across truthfulness categories, with highly polarized sentiments more common in false or misleading statements.</p></li>
<li><p><strong>Hugging Face Transformers</strong>: Similar patterns emerged, with more neutral tones linked to truthful statements and exaggerated tones correlated with misinformation.</p></li>
</ul>
</section>
<section id="limitations" class="level3">
<h3 class="anchored" data-anchor-id="limitations">Limitations</h3>
<p>POS tagging analysis did not yield strong correlations with truthfulness categories, suggesting that syntactic features alone may not be reliable indicators of misinformation.</p>
</section>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>The identification of linguistic markers of misinformation in political news articles is a critical endeavor in an era where fake news significantly influences public discourse and opinion. This study has aimed to explore the unique characteristics of misinformation, develop methodologies to detect it, and provide insights that can inform future research and practical interventions.</p>
<section id="key-findings" class="level2">
<h2 class="anchored" data-anchor-id="key-findings">Key Findings</h2>
<ol type="1">
<li><p><strong>Linguistic Patterns of Misinformation</strong>: Our analysis revealed that linguistic markers such as excessive subjectivity and emotional tone are significantly correlated with misinformation. Features like exaggerated sentiment, frequent use of hyperbolic language, and reliance on emotionally charged words were prominent in misleading content.</p></li>
<li><p><strong>The Role of Sentiment and Style</strong>: Sentiment analysis demonstrated that false or misleading statements often exhibit higher sentiment polarity compared to truthful articles. Misleading content tends to have more extreme positive or negative sentiments, while credible news is characterized by more neutral language. This finding aligns with previous studies suggesting that emotional manipulation is a hallmark of misinformation.</p></li>
<li><p><strong>Topic Clustering and Dimensionality Reduction</strong>: Unsupervised learning approaches, such as t-SNE and NMF, were effective in revealing distinct clusters within the dataset. These clusters highlighted clear distinctions in the types of statements categorized as true or false. Notably, certain clusters exhibited a higher proportion of false statements, indicating that clustering techniques could be a valuable tool for misinformation detection.</p></li>
<li><p><strong>Challenges and Limitations</strong>: Several limitations emerged from this study. First, the performance of the supervised models was hindered by the complexity and subtlety of linguistic cues associated with misinformation. The overlap of linguistic features between credible and misleading articles posed a significant challenge. Furthermore, part-of-speech tagging did not yield strong correlations with misinformation, indicating that syntactic features alone are insufficient for accurate classification. The reliance on pre-existing datasets like the LIAR dataset also constrained the generalizability of the findings.</p></li>
</ol>
</section>
<section id="implications" class="level2">
<h2 class="anchored" data-anchor-id="implications">Implications</h2>
<p>The results of this study have several important implications for researchers, fact-checkers, and media platforms:</p>
<p><strong>For Researchers</strong>: This study highlights the value of combining sentiment analysis and clustering techniques to identify misinformation. Future research could further refine these models and explore deeper semantic features, like rhetorical device analysis.</p>
<p><strong>For Fact-Checkers</strong>: The identification of specific linguistic markers can help fact-checking organizations develop tools to flag potentially misleading articles for review. This approach could be integrated into existing verification workflows to prioritize high-risk content.</p>
<p><strong>For Media Platforms</strong>: Social media and news platforms could incorporate machine learning models trained on linguistic markers to detect and flag content that shows signs of misinformation. While human oversight would remain essential, these models could serve as an early warning system for potentially harmful content.</p>
</section>
<section id="future-work" class="level2">
<h2 class="anchored" data-anchor-id="future-work">Future Work</h2>
<p>This project could be the groundwork for future exploration of linguistic markers of misinformation. Several avenues for future research are recommended:</p>
<p><strong>Enhanced Feature Engineering</strong>: Future studies could focus on developing new features, such as semantic embeddings and context-aware representations, to better capture the nuanced nature of misinformation.</p>
<p><strong>Improved Model Accuracy</strong>: Exploring advanced machine learning models, such as deep learning approaches (e.g., BERT or GPT-based classifiers), could significantly enhance classification accuracy.</p>
<p><strong>Broader Dataset Utilization</strong>: Incorporating diverse datasets beyond the LIAR dataset could increase generalizability and improve model robustness.</p>
<p><strong>Multi-Modal Analysis</strong>: Future research could analyze non-textual features, such as metadata, images, and social sharing patterns, to provide a holistic approach to misinformation detection.</p>
</section>
<section id="final-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h2>
<p>This study underscores the power and promise of machine learning in addressing the ongoing challenge of misinformation. By identifying and understanding the linguistic markers that differentiate misinformation from credible news, researchers and practitioners can contribute to a more informed and resilient society. While there is no “silver bullet” solution, the insights derived from this study provide a strong foundation for future innovations in automated misinformation detection. As the landscape of political communication continues to evolve, so too must our methods for safeguarding the integrity of information in public discourse.</p>


</section>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><a href="https://dl.acm.org/doi/10.1145/3137597.3137600" class="uri">https://dl.acm.org/doi/10.1145/3137597.3137600</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p><a href="https://arxiv.org/abs/1811.00770" class="uri">https://arxiv.org/abs/1811.00770</a><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p><a href="https://arxiv.org/abs/1708.07104" class="uri">https://arxiv.org/abs/1708.07104</a><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p><a href="https://doi.org/10.13140/2.1.4822.8166" class="uri">https://doi.org/10.13140/2.1.4822.8166</a><a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p><a href="https://doi.org/10.1080/21670811.2024.2305792" class="uri">https://doi.org/10.1080/21670811.2024.2305792</a><a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p><a href="https://doi.org/10.48550/arXiv.1705.00648" class="uri">https://doi.org/10.48550/arXiv.1705.00648</a><a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p><a href="https://paperswithcode.com/dataset/liar" class="uri">https://paperswithcode.com/dataset/liar</a><a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p><a href="https://www.mediacloud.org/documentation/search-api-guide" class="uri">https://www.mediacloud.org/documentation/search-api-guide</a><a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p><a href="https://newsapi.org/" class="uri">https://newsapi.org/</a><a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p><a href="https://trends.google.com/trends/explore?date=all&amp;q=%22fake%20news%22" class="uri">https://trends.google.com/trends/explore?date=all&amp;q=%22fake%20news%22</a><a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>